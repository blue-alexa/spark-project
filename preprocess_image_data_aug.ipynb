{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data for augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the following data structure:\n",
    "\n",
    "data/\n",
    "    train/\n",
    "        apple/\n",
    "            apple/\n",
    "                apple_0.png\n",
    "                apple_1.png\n",
    "                ...\n",
    "        banana/\n",
    "            banana/\n",
    "                banana_0.png\n",
    "                banana_1.png\n",
    "            ...\n",
    "    validation/\n",
    "        apple/\n",
    "            apple/\n",
    "                apple_0.png\n",
    "                apple_1.png\n",
    "                ...\n",
    "        banana/\n",
    "            banana/\n",
    "                banana_0.png\n",
    "                banana_1.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for data path group by class label\n",
    "\n",
    "data_dir = \".\\\\data\"\n",
    "set_name = \"train\"\n",
    "data_paths = glob.glob(os.path.join(data_dir, set_name, '*.png'))\n",
    "\n",
    "data_path_dict = {}\n",
    "\n",
    "for data_path in data_paths:\n",
    "    fname = os.path.basename(data_path)\n",
    "    label = fname.split(\"_\")[0]\n",
    "    if label not in data_path_dict.keys():\n",
    "        data_path_dict[label] = [data_path]\n",
    "    else:\n",
    "        data_path_dict[label].append(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = data_path_dict.keys()\n",
    "print (class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to individual class folder\n",
    "for key in data_path_dict.keys():\n",
    "    for data_path in data_path_dict[key]:\n",
    "        target_path = os.path.join(data_dir, set_name, key, key)\n",
    "        fname = os.path.basename(data_path)\n",
    "        if not os.path.exists(target_path):\n",
    "            os.makedirs(target_path)\n",
    "        shutil.move(data_path, os.path.join(target_path, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are resized to (150, 150)\n",
    "All augmented data are stored in folder .\\\\data\\\\train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = os.path.join(data_dir, \"train_aug\")\n",
    "\n",
    "os.mkdir(target_path)\n",
    "\n",
    "for key in class_labels:\n",
    "    source_path = os.path.join(data_dir, set_name, key)\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "    datagen_iter = datagen.flow_from_directory(\n",
    "                source_path,\n",
    "                target_size=(150, 150),\n",
    "                batch_size=100,\n",
    "                class_mode=None,\n",
    "                shuffle=False,\n",
    "                save_to_dir=target_path,\n",
    "                save_prefix=key)\n",
    "    count = 0\n",
    "    for img in datagen_iter:\n",
    "        if count == 10:\n",
    "            break\n",
    "        count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of sample per class\n",
    "data_paths = glob.glob(os.path.join(data_dir, \"train_aug\", '*.png'))\n",
    "\n",
    "class_count_dict = {}\n",
    "\n",
    "for data_path in data_paths:\n",
    "    fname = os.path.basename(data_path)\n",
    "    label = fname.split(\"_\")[0]\n",
    "    if not label in class_count_dict.keys():\n",
    "        class_count_dict[label] = 1\n",
    "    else:\n",
    "        class_count_dict[label] += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, count in class_count_dict.items():\n",
    "    print (\"Class: {:<15} sample counts: {:<15}\".format(name, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform image to feature and lable vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_manager(object):\n",
    "    \n",
    "    def __init__(self, data_dir, class_labels, image_size, set_name):\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        self.class_labels = class_labels\n",
    "        \n",
    "        self.num_class = len(self.class_labels)\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        \n",
    "        self.set_name = set_name\n",
    "        \n",
    "        self.load_set()   \n",
    "        \n",
    "    \n",
    "    def compute_label(self, label):\n",
    "        '''\n",
    "        Compute one-hot labels given the class size\n",
    "        '''    \n",
    "        one_hot = np.zeros(self.num_class)\n",
    "\n",
    "        idx = self.class_labels.index(label)\n",
    "\n",
    "        one_hot[idx] = 1.0\n",
    "\n",
    "        return one_hot\n",
    "\n",
    "\n",
    "    def compute_feature(self, image):\n",
    "        '''\n",
    "        Standardizing pixel value from [0, 255] to [-1, 1].\n",
    "        ''' \n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        \n",
    "        # image = (image / 255.0) * 2.0 - 1.0\n",
    "\n",
    "        return image      \n",
    "    \n",
    "            \n",
    "    def load_set(self):\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        label = []\n",
    "        \n",
    "        data_paths = glob.glob(os.path.join(self.data_dir, self.set_name, '*.png'))\n",
    "        \n",
    "        idx = np.arange(len(data_paths))\n",
    "        \n",
    "        np.random.shuffle(idx)\n",
    "\n",
    "        for i in idx:\n",
    "            \n",
    "            data_path = data_paths[i]\n",
    "\n",
    "            fname = os.path.basename(data_path)\n",
    "\n",
    "            img_label = fname.split(\"_\")[0]\n",
    "\n",
    "            if img_label in self.class_labels:\n",
    "\n",
    "                img = cv2.imread(data_path)\n",
    "\n",
    "                label.append(np.expand_dims(self.compute_label(img_label), axis=0))\n",
    "\n",
    "                features.append(np.expand_dims(self.compute_feature(img), axis=0))\n",
    "                \n",
    "        self.X = np.concatenate(features)\n",
    "        \n",
    "        self.Y = np.concatenate(label)\n",
    "        \n",
    "        del features, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \".\\\\data\"\n",
    "CLASS_LABELS = ['apple','banana','nectarine','plum','peach','watermelon','pear','mango','grape',\n",
    "                'orange','strawberry','pineapple','radish','carrot','potato','tomato','bellpepper',\n",
    "                'broccoli','cabbage','cauliflower','celery','eggplant','garlic','spinach','ginger']\n",
    "image_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_train = data_manager(data_dir, CLASS_LABELS, image_size, 'train_aug')\n",
    "print (dm_train.X.shape)\n",
    "print (dm_train.Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\".\\\\data\\\\X_train.npy\", dm_train.X)\n",
    "np.save(\".\\\\data\\\\Y_train.npy\", dm_train.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_test = data_manager(data_dir, CLASS_LABELS, image_size, 'val')\n",
    "print (dm_test.X.shape)\n",
    "print (dm_test.Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\".\\\\data\\\\X_test.npy\", dm_test.X)\n",
    "np.save(\".\\\\data\\\\Y_test.npy\", dm_test.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning the top layers of a a pre-trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"fine-tune\" the last convolutional block of the VGG16 model alongside the top-level classifier\n",
    "\n",
    "implement in 3 steps\n",
    "instantiate the convolutional base of VGG16 and load its weights\n",
    "add our previously defined fully-connected model on top, and load its weights\n",
    "freeze the layers of the VGG16 model up to the last convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "import math\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_train, Y_train, batch_size, steps):\n",
    "    while True:\n",
    "        for i in range(steps):\n",
    "            start_pos = i*batch_size\n",
    "            end_pos = (i+1)*batch_size\n",
    "            # yield batch size samples when does not meet ends, else yield rest of samples\n",
    "            if num_samples > (i * batch_size):\n",
    "                X_train_batch = X_train[start_pos:end_pos, :, :, :]\n",
    "                Y_train_batch = Y_train[start_pos:end_pos, :]\n",
    "            else:\n",
    "                X_train_batch = X_train[start_pos:, :, :, :]\n",
    "                Y_train_batch = Y_train[start_pos:, :]  \n",
    "            \n",
    "            # Rescale features    \n",
    "            X_train_batch = (X_train_batch / 255) * 2.0 - 1.0 \n",
    "            \n",
    "            yield X_train_batch, Y_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data \n",
    "X_train = np.load(\".\\\\data\\\\X_train.npy\")\n",
    "Y_train = np.load(\".\\\\data\\\\Y_train.npy\")\n",
    "X_test = np.load(\".\\\\data\\\\X_test.npy\")\n",
    "Y_test = np.load(\".\\\\data\\\\Y_test.npy\")\n",
    "print (X_train.shape, Y_train.shape)\n",
    "print (X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale features\n",
    "X_test = (X_test / 255) * 2.0 - 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = 'vgg16_weights_aug.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model_aug.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "num_samples = len(X_train)\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "steps = math.ceil(num_samples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = batch_generator(X_train, Y_train, batch_size, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(150,150,3))\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(25, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the model on top of the convolutional base\n",
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "# add checkpoint to save best model\n",
    "checkpoint = ModelCheckpoint(weights_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# check 5 epochs\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=5, mode='max')\n",
    "callbacks_list = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "          steps_per_epoch = steps,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.show()\n",
    "plt.savefig(\"fine_tune_VGG_acc_history_aug.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.show()\n",
    "plt.savefig(\"fine_tune_VGG_loss_history_aug.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"fine_tune_VGG_model_aug.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
